# ComfyUI-kaola-moss-ttsd

A ComfyUI custom node for [MOSS-TTSD](https://github.com/OpenMOSS/MOSS-TTSD), a high-quality text-to-spoken dialogue generation model.

## Features
- **Text-to-Speech Generation**: Generate high-fidelity speech from text.
- **Multi-Speaker Support (up to 5)**: Supports `[S1]` ~ `[S5]` tags for multi-speaker dialogue generation.
- **Voice Cloning**: Clone voices using short reference audio clips.

## Installation

> [!TIP]
> We strongly recommend creating a fresh **Python 3.12** environment to avoid dependency conflicts:
> ```bash
> conda create -n moss_ttsd python=3.12 -y && conda activate moss_ttsd
> pip install flash-attn --no-build-isolation
> ```

1.  Clone this repository into your `ComfyUI/custom_nodes` directory:
    ```bash
    cd custom_nodes
    git clone https://github.com/Startgame/ComfyUI-kaola-moss-ttsd.git
    ```

2.  Install dependencies:
    ```bash
    cd ComfyUI-kaola-moss-ttsd
    pip install -r requirements.txt
    ```

    *Note: For GPU acceleration, ensure you have a CUDA-compatible PyTorch installed.*

> [!WARNING]
> This node requires `transformers >= 5.0.0`. Please make sure your environment meets this requirement:
> ```bash
> pip install "transformers>=5.0.0"
> ```

## Usage

1.  From the node menu, select `Kaola` -> `MOSS-TTSD` -> `MOSS-TTSD Generation`.
2.  Input your dialogue text. Use tags like `[S1]` and `[S2]` to switch speakers.
    - Example: `[S1] Hello there! [S2] Hi! How are you?`
3.  (Optional) Connect `reference_audio_s1` and/or `reference_audio_s2` to provide voice reference clips for specific speakers.
4.  Connect the `AUDIO` output to a `PreviewAudio` or `SaveAudio` node.

## Generation Modes

| Mode | Reference Audio | Reference Text | Description |
|------|:-:|:-:|-------------|
| `generation` | ❌ | ❌ | Pure generation with random voices |
| `voice_clone` | ✅ | ❌ | Clone voice timbre from reference audio |
| `continuation` | ✅ | ✅ | Continue speaking after reference audio |
| `voice_clone_and_continuation` | ✅ | ✅ | Clone + continue (best for single speaker) |

### `generation`
No reference audio needed. The model generates speech with random voices. Good for quick testing.

### `voice_clone`
**Recommended for multi-speaker dialogue.** Provide reference audio for each speaker. The model encodes each speaker's audio separately and uses `[S1]`/`[S2]` tags in the text to switch voices.

- **Inputs**: `reference_audio_s1` (required), `reference_audio_s2` (optional)
- **Text format**: `[S1] Hello! [S2] Hi there!`

### `continuation`
The model treats the reference audio as "already spoken content" and continues from where it left off. Requires both reference audio AND reference text (the transcript of the reference audio).

- **Inputs**: `reference_audio_s1` + `reference_text_s1` (required)
- **Best for**: Single-speaker scenarios where you want natural continuation

### `voice_clone_and_continuation`
Combines voice cloning (reference in user message) with continuation (prompt audio in assistant message). Provides the strongest voice identity for single-speaker use cases.

- **Inputs**: `reference_audio_s1` + `reference_text_s1` (required)
- **Best for**: Single-speaker with precise voice matching
- **Note**: For multi-speaker dialogue, use `voice_clone` instead — continuation mode concatenates all reference audio, so the model tends to use the last speaker's voice

## Models

Two models are required:

| Model | HuggingFace ID | Size |
|-------|----------------|------|
| MOSS-TTSD | [OpenMOSS-Team/MOSS-TTSD-v1.0](https://huggingface.co/OpenMOSS-Team/MOSS-TTSD-v1.0) | ~7GB |
| MOSS-VoiceGenerator | [OpenMOSS-Team/MOSS-VoiceGenerator](https://huggingface.co/OpenMOSS-Team/MOSS-VoiceGenerator) | ~3GB |
| MOSS-SoundEffect | [OpenMOSS-Team/MOSS-SoundEffect](https://huggingface.co/OpenMOSS-Team/MOSS-SoundEffect) | ~3GB |
| MOSS-Audio-Tokenizer | [OpenMOSS-Team/MOSS-Audio-Tokenizer](https://huggingface.co/OpenMOSS-Team/MOSS-Audio-Tokenizer) | ~1GB |

### Auto Download
If models are not found locally, they will be **automatically downloaded** from HuggingFace on first run.

### Manual Download
Place models in the `ComfyUI/models/moss_ttsd/` directory:
```
ComfyUI/
└── models/
    └── moss_ttsd/
        ├── MOSS-TTSD-v1.0/
        ├── MOSS-VoiceGenerator/
        └── MOSS-Audio-Tokenizer/
```

You can use `huggingface-cli` to download:
```bash
huggingface-cli download OpenMOSS-Team/MOSS-TTSD-v1.0 --local-dir ComfyUI/models/moss_ttsd/MOSS-TTSD-v1.0
huggingface-cli download OpenMOSS-Team/MOSS-VoiceGenerator --local-dir ComfyUI/models/moss_ttsd/MOSS-VoiceGenerator
huggingface-cli download OpenMOSS-Team/MOSS-SoundEffect --local-dir ComfyUI/models/moss_ttsd/MOSS-SoundEffect
huggingface-cli download OpenMOSS-Team/MOSS-Audio-Tokenizer --local-dir ComfyUI/models/moss_ttsd/MOSS-Audio-Tokenizer
```

## Usage

### 1. MOSS-TTSD (Text-to-Speech)
- **Load Model**: Use `Load MOSS-TTSD Model` node.
- **Load Codec**: Use `Load MOSS-Audio Codec` node.
- **Generate**: Connect model and codec to `MOSS-TTSD Generate` node.

### 2. MOSS-VoiceGenerator (Voice Design)
- **Load Model**: Use `Load MOSS Voice Generator Model` node.
- **Generate**: Use `MOSS Voice Generator Generate` node.
    - **Instruction**: Describe the voice (e.g. "A clear, neutral voice", "年轻女性，温柔的声音").
    - **Text**: The initial content to speak with this voice.
    - **Output**: Returns an audio waveform that can be used as a *reference audio* for MOSS-TTSD `voice_clone` mode!

### 3. MOSS-SoundEffect (Audio Generation)
- **Load Model**: Use `Load MOSS Sound Effect Model` node.
- **Generate**: Use `MOSS Sound Effect Generate` node.
    - **Text**: Description (e.g., "birds chirping in a forest", "footsteps on wooden floor").
    - **Duration**: Target duration in seconds (approx 12.5 tokens/sec).
    - **Output**: Returns the generated sound effect audio.

## License
Apache 2.0 (Inherited from MOSS-TTSD)
